// composables/useCropperOcr.ts
import { ref, nextTick } from "vue"
import { useOcrService } from "@/composables/useOcrService"
import { useImageResizer } from "@/composables/useImageResizer"

export function useCropperOcr(options: any) {
    const { resizeImage } = useImageResizer()

    const cropperRef = ref<any>(null)
    const cropperSrc = ref<string | null>(null)
    const showCropper = ref(false)
    const croppedPreviewUrl = ref<string | null>(null)
    const ocrLoading = ref(false)

    const originalFile = ref<File | null>(null)
    const ocrRaw = ref("") // ‚úÖ store raw OCR text

    // pipeline refs from OCR service
    const {
        processFile,
        recheckHighlightsSmart,
        ingredientHighlights,
        ingredientsText,
        ingredientsTextZh,
        autoStatus,
        productName,
        showOk,
        detectedLanguage,
        progress,
        progressLabel
    } = useOcrService(options)

    const pendingRoi = ref<any>(null)

    function openCropper(file: File, roi: any = null) {
        if (cropperSrc.value) URL.revokeObjectURL(cropperSrc.value)
        originalFile.value = file
        cropperSrc.value = URL.createObjectURL(file)
        showCropper.value = true
        pendingRoi.value = roi
    }

    function onCropperReady() {
        if (!pendingRoi.value || !cropperRef.value) return

        const roi = pendingRoi.value
        // Small timeout to ensure the cropper has finished internal calculations
        setTimeout(() => {
            if (cropperRef.value) {
                cropperRef.value.setCoordinates((coordinates: any, imageSize: any) => {
                    console.log('üìê [Cropper] Applying ROI to image size:', imageSize);

                    // Convert percentages to absolute pixels
                    const width = (roi.width * imageSize.width) / 100;
                    const height = (roi.height * imageSize.height) / 100;
                    const left = (roi.left * imageSize.width) / 100;
                    const top = (roi.top * imageSize.height) / 100;

                    return { width, height, left, top };
                });
                pendingRoi.value = null;
            }
        }, 100);
    }

    async function confirmCrop() {
        if (!cropperRef.value) return
        const result = cropperRef.value.getResult()
        if (!result?.canvas) return

        ocrLoading.value = true
        try {
            const blob = await new Promise<Blob | null>((resolve) =>
                result.canvas.toBlob((b: Blob | null) => resolve(b), "image/jpeg", 0.9)
            )
            if (!blob) return

            if (croppedPreviewUrl.value) URL.revokeObjectURL(croppedPreviewUrl.value)
            croppedPreviewUrl.value = URL.createObjectURL(blob)

            const croppedFile = new File([blob], `cropped-${Date.now()}.jpg`, {
                type: "image/jpeg",
            })

            // Compress cropped for OCR
            const resizedCropped = await resizeImage(croppedFile)

            // ‚úÖ Run OCR once and store result
            const rawResult = await processFile(resizedCropped)
            if (rawResult?.ocrRaw) {
                ocrRaw.value = rawResult.ocrRaw
            }

            // --- üîπ Also prepare compressed original for back image ---
            if (originalFile.value) {
                const resizedBack = await resizeImage(originalFile.value)
                options?.setBackFile?.(resizedBack)
            }
        } catch (err) {
            console.error('‚ùå OCR failed in confirmCrop:', err)
            throw err // üëà rethrow to let handleConfirmCrop() know it failed
        } finally {
            ocrLoading.value = false
            showCropper.value = false
        }
    }

    function reset() {
        cropperSrc.value = null
        showCropper.value = false
        if (croppedPreviewUrl.value) {
            URL.revokeObjectURL(croppedPreviewUrl.value)
            croppedPreviewUrl.value = null
        }
        ingredientHighlights.value = []
        ingredientsText.value = ""
        ingredientsTextZh.value = ""
        productName.value = ""
        autoStatus.value = ""
        ocrRaw.value = "" // ‚úÖ reset too
        originalFile.value = null
    }

    function closeCropper() {
        if (cropperSrc.value) {
            URL.revokeObjectURL(cropperSrc.value)
            cropperSrc.value = null
        }
        showCropper.value = false
    }

    function recrop() {
        if (!originalFile.value) return
        if (cropperSrc.value) URL.revokeObjectURL(cropperSrc.value)
        cropperSrc.value = URL.createObjectURL(originalFile.value)
        showCropper.value = true
    }

    async function autoProcess(file: File, roi: any = null) {
        originalFile.value = file
        ocrLoading.value = true

        try {
            console.log('ü§ñ [AutoScan] Starting autoProcess...', JSON.stringify({ hasRoi: !!roi, roi }))
            let fileToProcess = file

            if (roi) {
                console.log('üìê [AutoScan] Applying ROI:', roi)
                const img = new Image()
                img.src = URL.createObjectURL(file)
                await new Promise((resolve) => (img.onload = resolve))

                const canvas = document.createElement('canvas')
                const scaleX = img.width / 100
                const scaleY = img.height / 100

                canvas.width = (roi.width * scaleX)
                canvas.height = (roi.height * scaleY)

                const ctx = canvas.getContext('2d')
                if (ctx) {
                    ctx.drawImage(
                        img,
                        roi.left * scaleX,
                        roi.top * scaleY,
                        roi.width * scaleX,
                        roi.height * scaleY,
                        0,
                        0,
                        canvas.width,
                        canvas.height
                    )

                    const blob = await new Promise<Blob | null>((resolve) =>
                        canvas.toBlob((b) => resolve(b), 'image/jpeg', 0.95)
                    )
                    if (blob) {
                        fileToProcess = new File([blob], `auto-${file.name}`, { type: 'image/jpeg' })
                        if (croppedPreviewUrl.value) URL.revokeObjectURL(croppedPreviewUrl.value)
                        croppedPreviewUrl.value = URL.createObjectURL(blob)
                        console.log('‚úÖ [AutoScan] Programmatic crop successful')
                    }
                }
                URL.revokeObjectURL(img.src)
            } else {
                console.warn('‚ö†Ô∏è [AutoScan] No ROI provided, using full image')
                if (croppedPreviewUrl.value) URL.revokeObjectURL(croppedPreviewUrl.value)
                croppedPreviewUrl.value = URL.createObjectURL(file)
            }

            // Run OCR pipeline
            const resized = await resizeImage(fileToProcess)
            const result = await processFile(resized)

            // Prepare compressed original for back image
            const resizedBack = await resizeImage(file)
            options?.setBackFile?.(resizedBack)

            return result
        } catch (err) {
            console.error('‚ùå [AutoScan] Auto OCR failed:', err)
            throw err
        } finally {
            ocrLoading.value = false
        }
    }

    return {
        cropperRef,
        cropperSrc,
        showCropper,
        croppedPreviewUrl,
        ocrLoading,
        openCropper,
        onCropperReady,
        autoProcess, // ‚úÖ Exported
        confirmCrop,
        closeCropper,
        recrop,
        reset,
        showOk,
        ingredientHighlights,
        ingredientsText,
        ingredientsTextZh,
        autoStatus,
        productName,
        recheckHighlightsSmart,
        ocrRaw,
        detectedLanguage,
        progress,
        progressLabel
    }
}
